{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "702a52d0-2806-4a93-8243-2e488aec74be",
   "metadata": {},
   "source": [
    "## Classifying Handwritten Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c49eba-4984-4d7c-852c-9f3315b8d649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811fbf4c-ea6b-4acf-82f1-0e6466a1e1c6",
   "metadata": {},
   "source": [
    "We use the toy digit dataset provided by scikit-learn.  \n",
    "\n",
    "(You may also find it fun later to try your hand at the MNIST dataset, one of the classic initial problems for budding machine-learning practicioners.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4483ce3b-9f1a-4c95-8d8c-584a4e0bbbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = sklearn.datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7614fcd-1d24-4ccb-96bb-f7fbe43b8450",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c23bbb-17b4-487c-abb7-8057737521fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = d.data\n",
    "y = d.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc9ad95-7a4f-4144-8442-9ea1285cd2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45562dc7-b7b2-496a-b19b-d2dc9bbb666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87995c4-adc7-4ed1-bf4c-44c0c058c176",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c552e99-3f17-47d0-b8f0-19d77c4dfc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530aa893-ce0d-485d-bf3e-b1d3cffe114b",
   "metadata": {},
   "source": [
    "The samples consist of 64 features, one for each pixel value of an 8x8 image array.  We can reshape the sample into an 8x8 array in order to visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d33b12-bd83-4c33-8245-b318894c4696",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = x[4].reshape(8,8)\n",
    "plt.imshow(sample, cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d39beb-140b-4d74-9a06-d4d8867b6614",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    plt.subplot(10,10,i+1)\n",
    "    sample = x[i].reshape(8,8)\n",
    "    plt.imshow(sample, cmap='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5342e65c-f978-40cd-b65e-d381fc69969d",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca6e0db-9d8d-4c7d-acf6-cd4fa30a7378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble\n",
    "rf_classifier = sklearn.ensemble.RandomForestClassifier(max_depth=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84bc854-8edf-4d36-8ff2-43197d35b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "        x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59257867-907f-4f56-8f24-2d2b3c7a7775",
   "metadata": {},
   "source": [
    "One catch to watch out for in splitting up your data into training and test sets:  stratification.\n",
    "\n",
    "Let's say you have a dataset that has 90% cat images and 10% dog images.  If you split your data and end up with 99% cats in your training data and 1% dogs, you'll be training your model on an unrepresentative sample.  (Sampling issues like this can be much more consequential and damaging than distinguishing cats from dogs!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbb5b75-2764-4572-b5f8-82765c30d9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y, width=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e762830-36e3-4446-a615-0839aa02e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_train, width=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a1e8c0-4a91-4118-a165-1250c3e07d59",
   "metadata": {},
   "source": [
    "Here the difference in percentages is noticeable but not too significant by eye.  Nevertheless, we can stratify our split properly by including the \"stratify\" parameter and assigning it our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7c4692-a0c8-4991-949e-7541a5bb34e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "        x, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93234e5-0dd8-469e-9f31-86078c148430",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y, width=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba58b0e-6f0f-4981-9ba5-9e6c7c1db608",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_train, width=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb23333-50a2-4775-90fe-8d7baaf48bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dc32e5-96ba-4c3d-8c1c-c62a95940db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_range = range(1, 20)\n",
    "depth_scores = []\n",
    "for d in depth_range:\n",
    "    rf_classifier = sklearn.ensemble.RandomForestClassifier(max_depth=d)\n",
    "    acc_score = cross_val_score(rf_classifier,\n",
    "                           x_train,\n",
    "                           y_train, \n",
    "                           cv=5, \n",
    "                           scoring='accuracy')\n",
    "    depth_scores.append(acc_score.mean())\n",
    "plt.scatter(depth_range, depth_scores)\n",
    "plt.xlabel('Value of Max Depth for RF Classifier')\n",
    "plt.ylabel('Cross-Validated Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a485a800-53fc-4b55-83d6-8545c8965f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = sklearn.ensemble.RandomForestClassifier(max_depth=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1306ad94-6261-43e9-acef-0e5b73f288cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461a6b69-ecd5-44b5-b7f7-923e6020d648",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier.predict(x_train[[7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d641c8-2015-4d73-9d7b-26216cb00c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0776086-6266-4500-92d6-3dc5e65a99c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575a0be2-f757-4263-b7b8-f93044740ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sklearn.metrics.confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aada2531-f496-489e-ba44-f7e128d8e10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cm,cmap='binary')\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2846feb-0f46-4b8c-b64f-4026af9424ca",
   "metadata": {},
   "source": [
    "In contrast with binary classification, calculating precision and recall (and etc) for multi-class classification problems can be computed in slightly different ways depending on how one does averaging. \n",
    "\n",
    "A macro-average will compute the metric independently for each class and then take the average (hence treating all classes equally), whereas a micro-average will aggregate the contributions of all classes to compute the average metric. \n",
    "\n",
    "In a multi-class classification setup, micro-average is preferable if you suspect there might be class imbalance (i.e you may have many more examples of one class than of other classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f54ef5-2011-48b8-8ff3-d46ed5d60eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {sklearn.metrics.accuracy_score(y_test, y_pred):.2%}\")\n",
    "print(f\"Precision: {sklearn.metrics.precision_score(y_test, y_pred, average='micro'):.2%}\")\n",
    "print(f\"Recall: {sklearn.metrics.recall_score(y_test, y_pred, average='micro'):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958d499b-6a50-4ceb-bd13-bbb610ff3297",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {sklearn.metrics.accuracy_score(y_test, y_pred):.2%}\")\n",
    "print(f\"Precision: {sklearn.metrics.precision_score(y_test, y_pred, average='macro'):.2%}\")\n",
    "print(f\"Recall: {sklearn.metrics.recall_score(y_test, y_pred, average='macro'):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a78858-15da-4bfe-bc09-a8a1b444109b",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb964029-aee4-4d0e-b9bb-cd7017cf59d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "lr_classifier = sklearn.linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc8bca1-5d79-4b59-b65a-5a716b282fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8d52bf-9812-4bcf-9091-03b0a9fb67d9",
   "metadata": {},
   "source": [
    "It will not be uncommon for you to run into scenarios in which you encounter errors when trying to train models.\n",
    "\n",
    "In such cases, they can be fruitful opportunities to consult the documentation and learn more about various training options.\n",
    "\n",
    "Here, the error message gives us clues about potentially insightful documentation.\n",
    "\n",
    "To fast-forward, it will be useful here for Logistic Regression if we rescale our sample data from being integer values over [0:16] to being continuous values scaled to have a normal distribution of values -> the sklearn StandardScaler will rescale the features to have 0 mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e18309-0f4e-4db0-883b-8d620926a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50fcba6-7350-4d37-aa8b-77bd2b36d2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4304d87-0b7d-44de-8afe-2b69fed14362",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1807c2fd-a0a8-44a4-9e56-8b97acf7e31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15deb6a-26b1-4556-8d50-ee52acdd813e",
   "metadata": {},
   "source": [
    "Here's the difference in image between original and rescaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c165e98-ddcd-400e-afc0-bf22af694041",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = x_train[7].reshape(8,8)\n",
    "plt.imshow(sample,cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4127af7a-4adf-4dc1-a12b-c0138bf78008",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = x_scaled[7].reshape(8,8)\n",
    "plt.imshow(sample,cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd33ad7-9e57-4dd5-b60c-a584a3c83255",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    plt.subplot(10,10,i+1)\n",
    "    sample = x_scaled[i].reshape(8,8)\n",
    "    plt.imshow(sample, cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68349695-2b06-47ba-8cb8-ca798cb288d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_classifier.fit(x_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502a4cb5-0e73-44a7-bd19-528d33af1865",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_classifier.predict(x_scaled[[7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ee8e4d-d7de-48af-bf95-6b038921c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a283fc6-521b-424a-95a8-3ae1587596c9",
   "metadata": {},
   "source": [
    "Our classifier was trained on scaled data, so we must scale any new data similarly (though we only need to do the transform now, not the fit.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f963882-735f-4667-b25a-95dc292c0bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bb8fca-4de4-4b3d-898b-b06e53cbe97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_classifier.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f6f814-d655-4855-8e8c-7f7039ed4158",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sklearn.metrics.confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c6d6a8-b5e4-49a7-a79e-7fd38ccf5dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cm,cmap='binary')\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb739227-2db8-4f30-8e0a-adc16139251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {sklearn.metrics.accuracy_score(y_test, y_pred):.2%}\")\n",
    "print(f\"Precision: {sklearn.metrics.precision_score(y_test, y_pred, average='micro'):.2%}\")\n",
    "print(f\"Recall: {sklearn.metrics.recall_score(y_test, y_pred, average='micro'):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1176f589-3cc7-4a8e-b690-a44401372a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {sklearn.metrics.accuracy_score(y_test, y_pred):.2%}\")\n",
    "print(f\"Precision: {sklearn.metrics.precision_score(y_test, y_pred, average='macro'):.2%}\")\n",
    "print(f\"Recall: {sklearn.metrics.recall_score(y_test, y_pred, average='macro'):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec64a6a0-480f-4bd2-9e77-4fbe300182b4",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf6198b-91f3-4092-b8e8-1084754965e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.naive_bayes\n",
    "nb_classifier = sklearn.naive_bayes.MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df7b837-5e7d-4def-b524-c96c506c302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa595d8-9a2c-41d6-bffd-71506c2bbf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0186daa3-0b0b-472b-9e56-b454a23ffe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sklearn.metrics.confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf03d350-a032-4d21-a972-ffd73e30117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cm,cmap='binary')\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e84f840-c900-49ab-88de-b813db5b9f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {sklearn.metrics.accuracy_score(y_test, y_pred):.2%}\")\n",
    "print(f\"Precision: {sklearn.metrics.precision_score(y_test, y_pred, average='micro'):.2%}\")\n",
    "print(f\"Recall: {sklearn.metrics.recall_score(y_test, y_pred, average='micro'):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca13900-2ea5-4816-8286-9cdd9da307a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {sklearn.metrics.accuracy_score(y_test, y_pred):.2%}\")\n",
    "print(f\"Precision: {sklearn.metrics.precision_score(y_test, y_pred, average='macro'):.2%}\")\n",
    "print(f\"Recall: {sklearn.metrics.recall_score(y_test, y_pred, average='macro'):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f63d964-be36-4266-a91c-59fd6c5e2f75",
   "metadata": {},
   "source": [
    "We could try doing the scaling here too to see if that improves the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adcd67d-6cc0-460b-a307-2d145e894d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2470680a-e87f-49f2-9e1c-81ef057dbdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled = sklearn.preprocessing.StandardScaler().fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df1a396-b7c4-48cf-af50-cef16599a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier.fit(x_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99b384e-7741-4c15-b448-d6d1621675da",
   "metadata": {},
   "source": [
    "For MultinomialNB, we actually can't use negative values in the training data.  A multinomial distribution is appropriate for discrete positive values (and actually indicates that the original scale is likely best).\n",
    "\n",
    "If we use MinMaxScaler, though, we'll get a similar standardization of the scaling, but now on the range of [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8f9c47-6c10-4438-9ed1-147e70708aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4ce614-1c21-449a-8e4e-b837eb6e8fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f816619-8388-448d-8ac4-5110564fd60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d02d75a-9568-48f6-a02d-d53d0901be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb_classifier.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992460aa-5280-44e6-b06f-3c8766f6ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sklearn.metrics.confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb32d17-435a-43c5-9812-5f5ee6fcaf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {sklearn.metrics.accuracy_score(y_test, y_pred):.2%}\")\n",
    "print(f\"Precision: {sklearn.metrics.precision_score(y_test, y_pred, average='micro'):.2%}\")\n",
    "print(f\"Recall: {sklearn.metrics.recall_score(y_test, y_pred, average='micro'):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec40b7b-17ec-4d51-a38b-77c8f8031ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {sklearn.metrics.accuracy_score(y_test, y_pred):.2%}\")\n",
    "print(f\"Precision: {sklearn.metrics.precision_score(y_test, y_pred, average='macro'):.2%}\")\n",
    "print(f\"Recall: {sklearn.metrics.recall_score(y_test, y_pred, average='macro'):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9eed26-91bc-4875-ab41-e6d13d25fc88",
   "metadata": {},
   "source": [
    "## Extra section: Binary Classification and the Precision/Recall Trade-Off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84e60cc-9a89-4451-a6f6-5fc9c5b943a3",
   "metadata": {},
   "source": [
    "In classification there is a trade-off between optimizing precision and optimizing recall.\n",
    "\n",
    "The following will allow you to quantify and visualize that trade-off, as well as make plots of the ROC curves (Receiver Operating Characteristic).\n",
    "\n",
    "ROC is useful for binary classification, when you have a strict population of false-negatives, true-positives, and etc.  Precision and recall are also more easily conceptualized in binary classification, when there is no ambiguity about handling multi-class classification.  Therefore, the below does classification for the classes Fives and Not-Fives.  (You can easily check for other numbers too by changing the 5 to, say, 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ff80ff-3f56-4b5d-8f21-c33fbcee365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_five = (y == 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d46bd54-eb81-4d77-9974-dad2dae7c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d534e3c4-60f8-4ab2-be74-1e3f41e9af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "        x, y_five, test_size=0.2, random_state=42, stratify=y_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbd587c-0865-4665-9244-c86553f96ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be804f77-1531-4ef1-b9bb-475284c98728",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_five) / y_five.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa932042-cc6e-45ac-9ef7-c8426532c097",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_test) / y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b76dab-8e24-4e76-990e-cfc988f19436",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_train) / y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09e7967-8ce3-4875-890d-fa9505ef0da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_classifier = sklearn.ensemble.RandomForestClassifier()\n",
    "rf_classifier.fit(x_train, y_train)\n",
    "rf_y_pred = rf_classifier.predict(x_test)\n",
    "print(f\"Accuracy: {sklearn.metrics.accuracy_score(y_test, rf_y_pred):.2%}\")\n",
    "print(f\"RF Precision: {sklearn.metrics.precision_score(y_test, rf_y_pred):.2%}\")\n",
    "print(f\"RF Recall: {sklearn.metrics.recall_score(y_test, rf_y_pred):.2%}\")\n",
    "cm = sklearn.metrics.confusion_matrix(y_test, rf_y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_classifier = sklearn.linear_model.LogisticRegression()\n",
    "x_train_scaled = sklearn.preprocessing.StandardScaler().fit_transform(x_train)\n",
    "x_test_scaled = sklearn.preprocessing.StandardScaler().fit_transform(x_test)\n",
    "lr_classifier.fit(x_train_scaled, y_train)\n",
    "lr_y_pred = lr_classifier.predict(x_test_scaled)\n",
    "print(f\"Accuracy: {sklearn.metrics.accuracy_score(y_test, lr_y_pred):.2%}\")\n",
    "print(f\"LR Precision: {sklearn.metrics.precision_score(y_test, lr_y_pred):.2%}\")\n",
    "print(f\"LR Recall: {sklearn.metrics.recall_score(y_test, lr_y_pred):.2%}\")\n",
    "cm = sklearn.metrics.confusion_matrix(y_test, lr_y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "nb_classifier = sklearn.naive_bayes.MultinomialNB()\n",
    "nb_classifier.fit(x_train, y_train)\n",
    "nb_y_pred = nb_classifier.predict(x_test)\n",
    "print(f\"Accuracy: {sklearn.metrics.accuracy_score(y_test, nb_y_pred):.2%}\")\n",
    "print(f\"NB Precision: {sklearn.metrics.precision_score(y_test, nb_y_pred):.2%}\")\n",
    "print(f\"NB Recall: {sklearn.metrics.recall_score(y_test, nb_y_pred):.2%}\")\n",
    "cm = sklearn.metrics.confusion_matrix(y_test, nb_y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4d890b-7026-4706-aa84-2778beea3a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_y_pred_train = rf_classifier.predict_proba(x_train)\n",
    "# lr_y_pred_train = lr_classifier.predict_proba(x_train_scaled)\n",
    "# nb_y_pred_train = nb_classifier.predict_proba(x_train)\n",
    "\n",
    "# rf_falsePositiveRate, rf_truePositiveRate, rf_thresholds = sklearn.metrics.roc_curve(y_train, rf_y_pred_train[:,1])\n",
    "# lr_falsePositiveRate, lr_truePositiveRate, lr_thresholds = sklearn.metrics.roc_curve(y_train, lr_y_pred_train[:,1])\n",
    "# nb_falsePositiveRate, nb_truePositiveRate, nb_thresholds = sklearn.metrics.roc_curve(y_train, nb_y_pred_train[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca43ed4-b797-48eb-bc84-2a8e8416e972",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_y_scores = sklearn.model_selection.cross_val_predict(rf_classifier, x_train, y_train, cv=3,\n",
    "                             method=\"predict_proba\")\n",
    "lr_y_scores = sklearn.model_selection.cross_val_predict(lr_classifier, x_train_scaled, y_train, cv=3,\n",
    "                             method=\"predict_proba\")\n",
    "nb_y_scores = sklearn.model_selection.cross_val_predict(nb_classifier, x_train, y_train, cv=3,\n",
    "                             method=\"predict_proba\")\n",
    "\n",
    "rf_falsePositiveRate, rf_truePositiveRate, rf_thresholds = sklearn.metrics.roc_curve(y_train, rf_y_scores[:,1])\n",
    "lr_falsePositiveRate, lr_truePositiveRate, lr_thresholds = sklearn.metrics.roc_curve(y_train, lr_y_scores[:,1])\n",
    "nb_falsePositiveRate, nb_truePositiveRate, nb_thresholds = sklearn.metrics.roc_curve(y_train, nb_y_scores[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7902dff3-c947-4eb0-ad8c-e6e1100b5b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))  # extra code â€“ not needed, just formatting\n",
    "plt.plot(rf_falsePositiveRate, rf_truePositiveRate, linewidth=2, color='black', label=\"RF ROC curve\")\n",
    "plt.plot(lr_falsePositiveRate, lr_truePositiveRate, linewidth=2, color='blue', label=\"LR ROC curve\")\n",
    "plt.plot(nb_falsePositiveRate, nb_truePositiveRate, linewidth=2, color='green', label=\"NB ROC curve\")\n",
    "plt.plot([0, 1], [0, 1], 'k:', label=\"Random classifier's ROC curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8b0c9c-2dd4-4713-84e1-748958d2b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_y_pred_train = rf_classifier.predict_proba(x_train)\n",
    "# rf_precisions, rf_recalls, rf_thresholds = sklearn.metrics.precision_recall_curve(y_train, rf_y_pred_train[:,1])\n",
    "\n",
    "# lr_y_pred_train = lr_classifier.predict_proba(x_train_scaled)\n",
    "# lr_precisions, lr_recalls, lr_thresholds = sklearn.metrics.precision_recall_curve(y_train, lr_y_pred_train[:,1])\n",
    "\n",
    "# nb_y_pred_train = nb_classifier.predict_proba(x_train)\n",
    "# nb_precisions, nb_recalls, nb_thresholds = sklearn.metrics.precision_recall_curve(y_train, nb_y_pred_train[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def6d1fc-201d-4542-a36f-c9c16f3188a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_precisions, rf_recalls, rf_thresholds = sklearn.metrics.precision_recall_curve(y_train, rf_y_scores[:,1])\n",
    "\n",
    "lr_precisions, lr_recalls, lr_thresholds = sklearn.metrics.precision_recall_curve(y_train, lr_y_scores[:,1])\n",
    "\n",
    "nb_precisions, nb_recalls, nb_thresholds = sklearn.metrics.precision_recall_curve(y_train, nb_y_scores[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dca8fd6-d88e-4cad-8305-b433fe9306ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(rf_thresholds, rf_precisions[:-1], \"b--\", label=\"RF Precision\", linewidth=2)\n",
    "plt.plot(rf_thresholds, rf_recalls[:-1], \"g-\", label=\"RF Recall\", linewidth=2)\n",
    "plt.axis([0, 1, 0, 1.1])\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(lr_thresholds, lr_precisions[:-1], \"b--\", label=\"LR Precision\", linewidth=2)\n",
    "plt.plot(lr_thresholds, lr_recalls[:-1], \"g-\", label=\"LR Recall\", linewidth=2)\n",
    "plt.axis([0, 1, 0, 1.1])\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(nb_thresholds, nb_precisions[:-1], \"b--\", label=\"NB Precision\", linewidth=2)\n",
    "plt.plot(nb_thresholds, nb_recalls[:-1], \"g-\", label=\"NB Recall\", linewidth=2)\n",
    "plt.axis([0, 1, 0, 1.1])\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
