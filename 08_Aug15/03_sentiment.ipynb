{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b469de05-cc72-4ef5-bb6f-cbb65d155aa9",
   "metadata": {},
   "source": [
    "# Sentiment and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be77db3-0ce7-471b-a5d2-0e89abf72168",
   "metadata": {},
   "source": [
    "For sentiment, we will look at VADER and NLTK's Sentiwordnet.\n",
    "\n",
    "* \"VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media.\"\n",
    "  * https://github.com/cjhutto/vaderSentiment\n",
    "  * nice example: https://rstudio-pubs-static.s3.amazonaws.com/79360_850b2a69980c4488b1db95987a24867a.html\n",
    "  \n",
    "* Sentiwordnet is a part of the NLTK library that includes sentiment scores for words on top of the information provided by wordnet.\n",
    "  * https://www.nltk.org/howto/sentiwordnet.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0609e1ea-e96c-4eaf-8d45-cc1e27e93d0f",
   "metadata": {},
   "source": [
    "## VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de7c903-55f3-4a9a-96e7-38cd17271ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import vader\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d539b3e-35fb-4f6a-880d-d93d54c79065",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = vader.SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b22e539-160e-408b-affa-aa224743f7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores('Luke, I am your father.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8153d0-a7d4-4e15-96df-a2ee7d3ff819",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores('NO!!!!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f766b61c-4954-4542-ba9f-8a1517e5c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores('I hate you.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dd71cf-217a-46ae-a6e1-009ad6adb93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores('I HATE you.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2951e5-3d31-432d-af9c-fba5233e3855",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores('I HATE you!!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b3a5de-7d04-4dd4-99d7-d01a59e10fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores('Thank you Dad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d534e5-87e8-4a39-8e8b-d9b630dac246",
   "metadata": {},
   "source": [
    "Try typing in a couple sentences to explore polarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39dfdde-dd16-4525-90b7-51e89ea8134a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbe442e1-7b1c-4bd7-aee2-23a9746f7c82",
   "metadata": {},
   "source": [
    "sia.polarity_scores(':D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aae029d-df16-49dc-bc80-e2c14fcf982d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores(':D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4892e59d-cb4b-464d-8fba-3defa42b954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores(':(')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb782224-9375-4146-a447-9762ccac6ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores('>:(')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82698a31-c951-46d6-8a41-7c93904f7b8a",
   "metadata": {},
   "source": [
    "Negation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795e7e3e-4eca-443e-8d44-1d43f1141c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores(\"I don't hate you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f9f15f-256b-4381-bfd5-0fc5b7744f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores(\"I don't not love you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a909c-2233-478e-ae12-88a607f63b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores(\"I love you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1844741a-0ebd-49f7-959d-c86c091879ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores(\"I LOVE you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58352a96-85a7-44f1-960d-0644d8ffcb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores(\"I really love you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bce382e-f835-409c-a863-f54a638dada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores(\"I am in love with you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44350d97-d710-4242-9902-437095bef368",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores(\"I am so in love with you\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696d5094-d82c-489e-a71b-c8d4ab1db48a",
   "metadata": {},
   "source": [
    "Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f3020e-954e-49b7-aff9-3d097bd1caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores(\"I usually hate shrimp but I loved this\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c037ced-16cc-4e9c-9bcf-fab42e7ec0a3",
   "metadata": {},
   "source": [
    "The part after the but takes precendence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc71d581-078a-471d-b26c-82b75edb7feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores(\"I usually hate shrimp and I loved this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a31387-3637-4b21-91c7-8b0e2a530fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores(\"I usually hate shrimp and I liked this\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e848a7b9-4330-4304-8b7d-857d4c84085d",
   "metadata": {},
   "source": [
    "## Cornell's movie data reviews\n",
    "\n",
    "https://www.cs.cornell.edu/people/pabo/movie-review-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80cfb8b-af16-4f72-a946-b15a76760712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the data files\n",
    "# read the lines of the files\n",
    "# and for every line, convert it into an ASCII string\n",
    "\n",
    "with open('rt-polaritydata/rt-polarity.neg','rb') as f:\n",
    "    negReviews = f.readlines()\n",
    "    for i in range(len(negReviews)):\n",
    "        negReviews[i] = str(negReviews[i], 'ascii', errors='ignore')\n",
    "        \n",
    "with open('rt-polaritydata/rt-polarity.pos','rb') as f:\n",
    "    posReviews = f.readlines()\n",
    "    for i in range(len(posReviews)):\n",
    "        posReviews[i] = str(posReviews[i], 'ascii', errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd76208-c301-428e-ae49-2cb0a64d13ac",
   "metadata": {},
   "source": [
    "We'll work with the data in Pandas.\n",
    "\n",
    "1. put the data into dataframes\n",
    "2. add a column for polarity scores\n",
    "3. concatenate the positive and negative reviews together into one collective dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e46343c-2be9-4831-ae2b-95647e0a5b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349c63bb-7dc1-4d30-ab28-e89d2604fb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpos = pd.DataFrame({'Review':posReviews, 'Polarity':1})\n",
    "dfneg = pd.DataFrame({'Review':negReviews, 'Polarity':-1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e9ff2-cbe5-4fa9-86ae-ac608299a3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582859d0-24d6-4e6f-ba34-6325e39a28a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall = pd.concat([dfpos,dfneg], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f6f91c-6a00-4aaf-a19e-275e6bee4a72",
   "metadata": {},
   "source": [
    "Let's look at a couple example entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36b4def-b355-4d0d-9534-ed1fa4f3e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2b3e13-31ba-4651-8b70-1cfce1f1d252",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f1b69f-1da0-4f6b-8100-6fbc78cf668d",
   "metadata": {},
   "source": [
    "Remember that `loc` is for indexing based on row and column labels, and that you can use Boolean indexing (i.e. you can use a true/false condition to retrieve specific rows or columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7f9442-bac1-4c57-a900-7a51bc17161a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfall.loc[dfall['Polarity']==1,'Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72092f7d-00f6-4f29-8baa-fa8fe79299f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfall.loc[dfall['Polarity']==-1,'Review'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80610af3-fafe-42a8-b28a-26b147ab279e",
   "metadata": {},
   "source": [
    "The following defines a function to return the Sentiment Intensity Analyzer's compound score for any review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580c3112-e8cb-4d2f-a38b-2571bcc2b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentiment(review):\n",
    "    return sia.polarity_scores(review)['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c5e4ad-fb09-419f-9251-452e502f354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "myreview = 'This movie tries to be Star Wars but fails miserably.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeaa653-ec36-4066-958a-7615356e8b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "getSentiment(myreview)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eef12a-b99f-4d56-a5cc-cac679cd0bb8",
   "metadata": {},
   "source": [
    "We're going to make a new list of the review scores from Vader.\n",
    "\n",
    "We'll use list comprehension to streamline this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9fba89-3fe5-4a42-8656-edb43c6f02a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example list comprehension\n",
    "[i for i in [1,2,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a293330c-acbd-4916-8104-647bb995c521",
   "metadata": {},
   "outputs": [],
   "source": [
    "[a for a in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd90ace-71d0-4f32-b5c9-e6dd61267fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in [2,3,6,5,7,8,4] if x > 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cfeb68-e328-4d9f-a511-3459979328ce",
   "metadata": {},
   "source": [
    "The following makes a list of Vader's review scores for every row of the dataframe `dfall` and adds the scores into a new column `VaderSentiment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8903f397-5867-4319-8f98-24ce54decd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall['VaderSentiment'] = [getSentiment(review) for review in dfall['Review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810dc7ec-3ab5-4c40-b7f2-57307779ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8562a817-43b6-432c-81ac-3fcf8d9ac837",
   "metadata": {},
   "source": [
    "Count the number of rows where Polarity = 1 and Vader Sentiment is > 0 (that is, where Vader would classify the sentiment as being positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56e88cc-88ff-451b-89d9-5b3f0e0ae726",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall.loc[(dfall['Polarity']==1) & (dfall['VaderSentiment']>0),'Review'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b55601a-edc2-404f-a832-eedf03078b15",
   "metadata": {},
   "source": [
    "We can quantify the percentage correctly classified by Vader as positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc15a9fe-3a63-48f5-8c1e-8524dfd57f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = dfall.loc[(dfall['Polarity']==1) & (dfall['VaderSentiment']>0),'Review'].count()\n",
    "total = dfall.loc[(dfall['Polarity']==1),'Review'].count()\n",
    "correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7938a0d9-003e-4729-9818-e50d54b72a33",
   "metadata": {},
   "source": [
    "And the percentage correctly classified as negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beb7700-3764-44ac-8a3b-322021b33936",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = dfall.loc[(dfall['Polarity']==-1) & (dfall['VaderSentiment']<0),'Review'].count()\n",
    "total = dfall.loc[(dfall['Polarity']==-1),'Review'].count()\n",
    "correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47a2f00-8bfb-42e4-ab46-b041d1272828",
   "metadata": {},
   "source": [
    "Less than 50% correct for the negative sentiments!!  Worse than random chance.\n",
    "\n",
    "Let's check out a couple examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a3534-4779-4df6-92ae-bd51300230db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dfall.loc[(dfall['Polarity']==-1)][:5].index:\n",
    "    print(dfall.loc[i,'VaderSentiment'], ':', dfall.loc[i,'Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8877e8c-f1e1-41fb-9871-9fac77164f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "getSentiment('''exploitative and largely devoid of the depth or \n",
    "             sophistication that would make watching such a graphic \n",
    "             treatment of the crimes bearable''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc72f28-7b20-41bb-b3ff-aa093d940373",
   "metadata": {},
   "source": [
    "Let's look at the distribution of scores to see if that provides any insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca72de9-aa13-435c-90f1-f7956784e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall.loc[dfall['Polarity']==1, 'VaderSentiment'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cf7b0b-9b6f-44d7-a248-d3036a435650",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall.loc[dfall['Polarity']==-1, 'VaderSentiment'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb5ee2c-b315-43a8-ab64-5ad45eb6cb26",
   "metadata": {},
   "source": [
    "The total accuracy is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70131ba2-9c00-414b-a61c-29f8752315e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "poscorrect = dfall.loc[(dfall['Polarity']==1) & (dfall['VaderSentiment']>0),'Review'].count()\n",
    "negcorrect = dfall.loc[(dfall['Polarity']==-1) & (dfall['VaderSentiment']<0),'Review'].count()\n",
    "total = dfall['Review'].count()\n",
    "(poscorrect + negcorrect)/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0943c1-439a-4c89-a3fe-ab3b9c9d3d35",
   "metadata": {},
   "source": [
    "We can encapsulate the essential code from above into a function to generalize the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a89691-f7ee-4fb8-8401-09bcd43c5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runScoring(dfall):\n",
    "    poscorrect = dfall.loc[(dfall['Polarity']==1) & (dfall['VaderSentiment']>0),'Review'].count()\n",
    "    postotal = dfall.loc[(dfall['Polarity']==1),'Review'].count()\n",
    "\n",
    "    negcorrect = dfall.loc[(dfall['Polarity']==-1) & (dfall['VaderSentiment']<0),'Review'].count()\n",
    "    negtotal = dfall.loc[(dfall['Polarity']==-1),'Review'].count()\n",
    "\n",
    "    total = dfall['Review'].count()\n",
    "\n",
    "    print('The accuracy for positive reviews is: ' + str(poscorrect/postotal*100) + '%')\n",
    "    print('The accuracy for negative reviews is: ' + str(negcorrect/negtotal*100) + '%')\n",
    "    print('The overall accuracy is: ' + str((poscorrect+negcorrect)/total*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f4253c-07d2-4f92-8a93-e0d4041c4466",
   "metadata": {},
   "outputs": [],
   "source": [
    "runScoring(dfall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65611c10-11aa-4980-9b22-422c18afb2bd",
   "metadata": {},
   "source": [
    "# Sentiwordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e463f141-23d6-446b-a747-2266b4943746",
   "metadata": {},
   "source": [
    "NLTK includes functionality for using Sentiwordnet, a lexical tool that includes information about words' synsets (words that are like synonyms) and thereby can be used to help assess sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7afb25-8de9-49b3-815a-7e3263d619d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "nltk.download('sentiwordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dec00fd-32b4-4b00-ad00-d95c535adae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(swn.senti_synsets('funny'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3fa280-0118-4440-b595-92f2338573d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(swn.senti_synsets('funny'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e56419-b4a9-48f8-9776-f88673fec3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(swn.senti_synsets('funny'))[0].pos_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6230bae-cef7-4b44-add6-76928146e6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(swn.senti_synsets('funny'))[0].neg_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae36376-9014-46a9-839a-c946fd8afdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(swn.senti_synsets('funny'))[0].obj_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fd6108-7d0e-49c1-bbf5-ab0652c533d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(swn.senti_synsets('funny')):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea0d0b8-2113-4806-b9cb-ae7c2a28d0dc",
   "metadata": {},
   "source": [
    "`wordnet` allows us to get definitions of the synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae94899-3309-456c-8caf-9d6df3ca5a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e030668-8a70-4c67-98db-93b2e2298cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in wordnet.synsets('funny'):\n",
    "    print(i,i.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0650eaa-5d8b-4f84-8e5b-327f0abe8a4b",
   "metadata": {},
   "source": [
    "Consider one review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32582e0c-8e1b-490b-b0ab-db8f95cc1bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall.loc[0,'Review']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e870d3-3963-4d5c-8856-89466008c4bd",
   "metadata": {},
   "source": [
    "We could use the synset polarity scores of individual words in a sentence to manually score a review's sentiment.\n",
    "1. break up a sentence into words\n",
    "2. remove stopwords\n",
    "3. sum the synset scores of the words\n",
    "  * for each word, a simple first attempt is to take all the synsets and (a) add the positive score if the positive score is largest or (b) subtract the negative score if the negative score is largest, and then divide the total sum of all synset scores by the number of synsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea9e5fe-284e-4a33-905f-a740a524b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "myStopWords = list(punctuation) + stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5580e781-c5e4-46ed-ab79-3e4ca7529b93",
   "metadata": {},
   "source": [
    "Example of breaking a review into a list of individual words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d34d60-ad0d-41f8-a6a3-a53d9a6ed69c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[w for w in word_tokenize(dfall.loc[0,'Review'].lower())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ba25a7-cfe8-4024-8566-609116599db3",
   "metadata": {},
   "source": [
    "The same list, but with stopwords removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bf61c3-e16e-4a62-aba2-b8307bdbc49f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[w for w in word_tokenize(dfall.loc[0,'Review'].lower()) if w not in myStopWords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2b8263-7de5-4bc4-a903-199f25a4f61b",
   "metadata": {},
   "source": [
    "Here's our function for getting the average synset scores of words in a review and summing them all up to get a polarity score for the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bd4364-09db-43aa-9236-714e8dbc1ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveSentiment(review):\n",
    "    reviewPolarity = 0.0\n",
    "    words = [w for w in word_tokenize(review.lower()) if w not in myStopWords]\n",
    "    for word in words:\n",
    "        sentScore = 0.0\n",
    "        if len(list(swn.senti_synsets(word))) > 0:\n",
    "            for i in list(swn.senti_synsets(word)):\n",
    "                if i.pos_score() > i.neg_score():\n",
    "                    sentScore += i.pos_score()\n",
    "                else:\n",
    "                    sentScore -= i.neg_score()\n",
    "            reviewPolarity += sentScore / len(list(swn.senti_synsets(word)))\n",
    "    \n",
    "    return reviewPolarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162b1717-29de-403e-8771-951bef64b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "naiveSentiment(dfall.loc[0,'Review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cc4574-1239-4475-9b35-120765300176",
   "metadata": {},
   "source": [
    "Make a new column in our main dataframe that uses our sentiwordnet-based scoring system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42721eb5-b4ea-48ed-a471-3974faf2e6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall['naiveSentiment'] = [naiveSentiment(review) for review in dfall['Review']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce701e91-1ebd-4209-a7e4-4663848d9550",
   "metadata": {},
   "source": [
    "Copy the above `runScoring` for a final method assessment, but now add an extra variable for specifying the particular sentiment column to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de60e0b8-ad80-4bfa-9aa5-3172bbe06946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runScoring(dfall,sentimentMethod):\n",
    "    poscorrect = dfall.loc[(dfall['Polarity']==1) & (dfall[sentimentMethod]>0),'Review'].count()\n",
    "    postotal = dfall.loc[(dfall['Polarity']==1),'Review'].count()\n",
    "\n",
    "    negcorrect = dfall.loc[(dfall['Polarity']==-1) & (dfall[sentimentMethod]<0),'Review'].count()\n",
    "    negtotal = dfall.loc[(dfall['Polarity']==-1),'Review'].count()\n",
    "\n",
    "    total = dfall['Review'].count()\n",
    "\n",
    "    print('The accuracy for positive reviews is: ' + str(poscorrect/postotal*100) + '%')\n",
    "    print('The accuracy for negative reviews is: ' + str(negcorrect/negtotal*100) + '%')\n",
    "    print('The overall accuracy is: ' + str((poscorrect+negcorrect)/total*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a143af-5902-4501-b2d2-fafc54dde048",
   "metadata": {},
   "outputs": [],
   "source": [
    "runScoring(dfall, 'VaderSentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb3d15-ee7b-4008-b2c1-4defd629724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "runScoring(dfall, 'naiveSentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd01565-f264-46a8-afc7-124c357d03aa",
   "metadata": {},
   "source": [
    "This method with synset scoring does a slightly better job at classification, though admittedly its method of approach is relatively simplistic.\n",
    "\n",
    "Let's again look at the distribution of scores for the reviews that have a real positive or negative polarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a80bcc-1ac2-462d-a61f-5a8f8afa8c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall.loc[dfall['Polarity']==1, 'naiveSentiment'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d03c09-c33c-44c5-b116-1f84affa20d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall.loc[dfall['Polarity']==-1, 'naiveSentiment'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3511c6bf-2168-4f43-b76e-13d41d244340",
   "metadata": {},
   "source": [
    "There are many shortcomings.  But actually, one shortcoming is very easy to spot:  Vader properly accounts for negation while our naive sentiment scorer with synset averaging does not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7be3ccf-5ec5-4f50-aaf7-7123ea18ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "getSentiment('this restaurant is lousy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6bd98b-3ab9-40aa-b703-d442e53524cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "getSentiment('this restaurant is not lousy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f97e631-cd96-43a1-9bdf-541c66c42cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "naiveSentiment('this restaurant is lousy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0a4450-7b62-42fc-8a29-f1c66058cd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "naiveSentiment('this restaurant is not lousy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf9c38f-2d2e-453f-a673-4b39cb8c2e54",
   "metadata": {},
   "source": [
    "Why is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3b15a3-0405-49be-a122-64ce734d9654",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(myStopWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c979303f-a0eb-43b3-a74c-69fdc59fd623",
   "metadata": {},
   "source": [
    "Note that \"not\" is in the stopwords -> it's been completely dropped before our naiveSentiment scorer ran."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c406cc0-cff7-444f-b971-ad336a4d0b23",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af659473-ae24-43d9-91b1-e7cfaea07b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b752b658-1cb5-47a9-b7d9-c3861f0e5993",
   "metadata": {},
   "source": [
    "We can manually split our dataframe into training and test sets (and make sure that we keep a 50/50 split in each of positive/negative reviews)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8881bb85-91b3-41af-bb48-2c6c2f5c8c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainNum = 2000\n",
    "testNum = 5331 - trainNum\n",
    "\n",
    "trainPosReviews = dfall.loc[dfall['Polarity']==1][:trainNum]\n",
    "testPosReviews = dfall.loc[dfall['Polarity']==1][trainNum:]\n",
    "\n",
    "trainNegReviews = dfall.loc[dfall['Polarity']==-1][:trainNum]\n",
    "testNegReviews = dfall.loc[dfall['Polarity']==-1][trainNum:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b987cc49-d31b-4688-946f-fe76d55031ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainPosReviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d244d74-0e9d-4777-9d35-b7d5431adc94",
   "metadata": {},
   "source": [
    "We're going to use word frequencies to get our probabilities for Bayesian estimation.\n",
    "\n",
    "The following makes lists of words found in the positive reviews and in the negative reviews (and drops stopwords).  It also makes a list of all words called `vocab`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a50443-8e83-4441-a310-82f23f21d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "posWords = []\n",
    "negWords = []\n",
    "vocab = []\n",
    "for i in trainPosReviews.index:\n",
    "    words = [w for w in word_tokenize(trainPosReviews.loc[i,'Review'].lower()) if w not in myStopWords]\n",
    "    for word in words:\n",
    "        if word not in posWords:\n",
    "            posWords.append(word)\n",
    "        if word not in vocab:\n",
    "            vocab.append(word)\n",
    "for i in trainNegReviews.index:\n",
    "    words = [w for w in word_tokenize(trainNegReviews.loc[i,'Review'].lower()) if w not in myStopWords]\n",
    "    for word in words:\n",
    "        if word not in negWords:\n",
    "            negWords.append(word)\n",
    "        if word not in vocab:\n",
    "            vocab.append(word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1701ba-4ac1-4b2a-b736-334755b158f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here is the list of all words retained:\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e5941b-9575-4e43-ab5a-71b75e9ac14a",
   "metadata": {},
   "source": [
    "Each review is made into a \"feature vector\".  This vector is a long dictionary -- every word in the total `vocab` list is a key and for each key, the value is set to `1` if the word is in the review and to `0` if the word is not in the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630f3a83-8046-4fbe-904a-ec3a8151a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFeatureVector(review):\n",
    "    words = [w for w in word_tokenize(review.lower()) if w not in myStopWords]\n",
    "    featureVector = {}\n",
    "    for word in vocab:\n",
    "        if word in words:\n",
    "            featureVector[word] = 1\n",
    "        else:\n",
    "            featureVector[word] = 0\n",
    "    return featureVector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d088554-a51f-421e-8611-61e2758ef433",
   "metadata": {},
   "source": [
    "Here's an example of the feature vector for a review that reads \"This is my favorite movie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590f0a1f-231c-45f3-bdfd-28757cef8cf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "makeFeatureVector('This is my favorite movie')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becb1e26-7146-4b79-a361-f6cb0dbd41ec",
   "metadata": {},
   "source": [
    "Make our training data by making a list that contains the review strings and their respective Polarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cde1c8-5443-448e-aa65-40de4f11a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = []\n",
    "for i in trainPosReviews.index:\n",
    "    trainingData.append((trainPosReviews.loc[i,'Review'],trainPosReviews.loc[i,'Polarity']))\n",
    "for i in trainNegReviews.index:\n",
    "    trainingData.append((trainNegReviews.loc[i,'Review'],trainNegReviews.loc[i,'Polarity']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add3d1b9-6980-43ff-b5eb-402fd6ae78d7",
   "metadata": {},
   "source": [
    "Here are the first five items of our training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9620c48-13d6-44db-bed4-f411fe0c9b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff3d76f-41e8-4f8e-b35d-49fcda91899d",
   "metadata": {},
   "source": [
    "And here's an example negative review contained in our training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eb4bfc-313d-4153-82f9-ff2624b5ac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData[2500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fce073-55d3-4e10-b17a-871c119cd861",
   "metadata": {},
   "source": [
    "As part of our steps to pre-process the data, we need to convert each review in our training data into a feature vector.\n",
    "\n",
    "To do this, we can use `nltk.classify.apply_features`.  We pass in our training dataset, as well as the function that we have defined above to make a feature vector out of a review, `makeFeatureVector`.  `apply_features` applies the function to convert every review contained in the training dataset into a feature vector, and the result gets returned and then stored into our new variable `trainingFeatureVectors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d29d867-6c3e-4e36-bba5-f1c965129737",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingFeatureVectors = nltk.classify.apply_features(makeFeatureVector, trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277d7a0b-a9d9-40d4-816a-f66b7cc8a228",
   "metadata": {},
   "source": [
    "Here's how the first review turned out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d983aacc-d270-465d-b94c-73a45f022c2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainingFeatureVectors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c1f683-e701-4c0e-aedd-3d06407fe6fa",
   "metadata": {},
   "source": [
    "NLTK has a module `NaiveBayesClassifier`.  Rather than using `fit` as we are used to from scikit-learn, here we use the `train` method.  Furthermore, the data passed into the `train` method has both the independent variable (the review's feature vector) and the dependent variable (the polarity score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85485af7-d0ee-47d8-a20b-cdf82d356756",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedClassifier = nltk.NaiveBayesClassifier.train(trainingFeatureVectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b191f23-4059-4801-92e5-6af441614e1e",
   "metadata": {},
   "source": [
    "Now that we have trained our classifier, we can use it to predict the sentiment score of any review.\n",
    "\n",
    "To make a prediction, we need to convert the review into a feature vector and then pass that feature vector into our trained classifier to get the prediction.\n",
    "\n",
    "The following functions carries out those two steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9457f2b4-83e8-4c1f-9cd8-fd4094a06fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayesSentimentCalculator(review):\n",
    "    problemFeatureVector = makeFeatureVector(review)\n",
    "    return trainedClassifier.classify(problemFeatureVector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753d628a-e2b5-4060-820e-ceb70734479d",
   "metadata": {},
   "source": [
    "Here are two test examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08eace4-0a93-400e-8be9-c51c9fd8196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "naiveBayesSentimentCalculator(\"What an awesome movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4f4aef-c8d4-4074-a2fe-5f711f4d96fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "naiveBayesSentimentCalculator(\"What a terrible movie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cc3759-f183-4b5f-973a-120987653c12",
   "metadata": {},
   "source": [
    "As you can see, since our Polarity scores were 1 and -1, our classifier gives us 1 and -1 as possible classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399ffc80-7824-4c77-92ce-bf77538f854a",
   "metadata": {},
   "source": [
    "To quantify how our classifier performs, we now pass in the test data to produce predicted sentiment scores that we can compare against the actual test data's Polarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281458c6-6a2b-4627-b431-d74354bbea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "testPosReviews['naiveBayesSentiment'] = [naiveBayesSentimentCalculator(review) for review in testPosReviews['Review']]\n",
    "testNegReviews['naiveBayesSentiment'] = [naiveBayesSentimentCalculator(review) for review in testNegReviews['Review']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9880e6f7-dca1-40c1-a913-0e5b8fb76b68",
   "metadata": {},
   "source": [
    "The following function assesses the accuracy of our Naives Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a58b6d-7d2e-4368-94e5-e4de3cfa1d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runScoringNB():\n",
    "    poscorrect = testPosReviews.loc[(testPosReviews['Polarity']==1) & (testPosReviews['naiveBayesSentiment']==1),'Review'].count()\n",
    "    postotal = testPosReviews.loc[(testPosReviews['Polarity']==1),'Review'].count()\n",
    "\n",
    "    negcorrect = testNegReviews.loc[(testNegReviews['Polarity']==-1) & (testNegReviews['naiveBayesSentiment']==-1),'Review'].count()\n",
    "    negtotal = testNegReviews.loc[(testNegReviews['Polarity']==-1),'Review'].count()\n",
    "\n",
    "    total = testPosReviews['Review'].count() + testNegReviews['Review'].count()\n",
    "\n",
    "    print('The accuracy for positive reviews is: ' + str(poscorrect/postotal*100) + '%')\n",
    "    print('The accuracy for negative reviews is: ' + str(negcorrect/negtotal*100) + '%')\n",
    "    print('The overall accuracy is: ' + str((poscorrect+negcorrect)/total*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46d7887-fa9f-4357-8540-3126f79d4d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "runScoring(dfall, 'VaderSentiment')\n",
    "runScoring(dfall, 'naiveSentiment')\n",
    "runScoringNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b02812-f1e4-42fe-bf7c-a5882e28b5f2",
   "metadata": {},
   "source": [
    "The accuracy here is starting to improve!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
