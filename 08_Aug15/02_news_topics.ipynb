{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4edc1037-9b05-44c6-8c07-219f69328b77",
   "metadata": {},
   "source": [
    "# Topic modeling\n",
    "\n",
    "We are going to look at data from the [20 Newsgroups](http://qwone.com/~jason/20Newsgroups/) dataset.  These are postings to newsgroups in 20 different categories.\n",
    "\n",
    "Scikit-learn has a function for downloading the data.  See: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html\n",
    "\n",
    "## LDA\n",
    "\n",
    "Latent Dirichlet Allocation:  a topic model that generates topics based on a set of documents' word frequencies.\n",
    "\n",
    "* Get a \"dictionary\" that has IDs for all the words along with a record of their word frequencies.\n",
    "* Use our \"bag of words\" to generate a list for each document containing its words and their frequencies\n",
    "* Use gensim to generate an LDA model\n",
    "\n",
    "## Gensim\n",
    "\n",
    "* \"Gensim is an open-source library for unsupervised topic modeling and natural language processing, using modern statistical machine learning.\"\n",
    "* [gensim website](https://radimrehurek.com/gensim/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011b5d42-d37e-4e71-ab13-d99e91048d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b361ee-d241-4bf7-b3ef-0a32dcc2e62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_20newsgroups(remove=(\"headers\", \"footers\", \"quotes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad16c2c1-2207-4233-8281-307161fadbed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73716a29-da6e-41cb-8436-ed5672d03e06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae459b3-e221-441d-81c1-02ea865a25ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0267475a-529a-48cc-a91d-b3fde92af8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc714e58-530e-4693-be86-97f4ff144588",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa66e72-9d94-43dd-977a-c73fedab972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7924c31b-452b-437a-a765-08e932ccec12",
   "metadata": {},
   "source": [
    "We use NLTK to pre-process the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bae2b9-1a9b-4a0d-9b72-2ba9c42c8580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512c234a-f674-40a7-8311-e21aa308148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "myStopWords = list(punctuation) + stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab39c868-8420-4873-9991-1765a22aab75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[w for w in word_tokenize(x[0].lower()) if w not in myStopWords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a948b9-75b6-424e-94b3-6c16700b2287",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for i in x:\n",
    "    docs.append([w for w in word_tokenize(i.lower()) if w not in myStopWords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d53c1a8-cb62-4119-94bb-178619912b52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b80233-5cc9-43f1-a2ed-d69815f39d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "#from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2e3130-fb17-4e22-b775-bf6e98f878fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e877102-13db-43ed-82d1-551ec474d977",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_stemmed = []\n",
    "for i in docs:\n",
    "    docs_stemmed.append([p_stemmer.stem(w) for w in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5436a74-4f45-4e7d-96ca-12e7ef806c45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs_stemmed[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8092a60b-32b1-4173-aa67-794881638608",
   "metadata": {},
   "source": [
    "Here we use gensim to make the dictionary and corpus structures, and to employ the LDA model to extract groups (aka topics) and the distribution of words for each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2294d9-ab78-42e0-83ca-321bc381503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da8cbe2-dc2f-495a-b8b5-983e296d9b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(docs_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde8095b-24a9-49c7-8f10-a224696616e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c28ea8a-5962-49e1-aa9d-2f14900865ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=10, no_above=0.5)\n",
    "# could also trim with keep_n=1000 or similar to keep only the top words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0932895-df99-4a9b-be70-039fdc2a50ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d17faa4-eca1-4647-a0f7-66163435e2b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679a4c55-b149-47c6-ac03-8d007b2e7e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dictionary.token2id['patient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b986523-2eb2-4555-935a-5de37eb9f84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary[1668]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa8266d-bb5d-4626-95a1-91d2df9dd084",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in docs_stemmed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5383fd9b-0267-4d5c-ab54-eb06e8c082bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1baa1f-ba7d-4242-bec7-0d95fb484e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary[276]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de5415e-1ef5-477c-b7a2-5ce47d6e4e36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs_stemmed[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284854d0-92a4-482e-937e-904e93e21be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordid = corpus[30][0]\n",
    "print(dictionary[wordid[0]],wordid[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5282e3-5ec2-47d0-b5b6-2875af2e5360",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in corpus[30]:\n",
    "    print(dictionary[i[0]], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f364d19a-d545-485b-bb5b-25be3cfba874",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, \n",
    "                                           num_topics=20, \n",
    "                                           id2word = dictionary, \n",
    "                                           passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01662301-327f-421a-9908-83ab0c969cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel.show_topics(num_topics=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34abdd71-d58e-447b-a5c1-94e91090ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ldamodel.print_topics(num_topics=20, num_words=20):\n",
    "    print(i[0])\n",
    "    print(i[1])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d701e5-1f5f-484e-bdd1-7bb2e5ab634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f68fcae-e88b-4759-bf47-393a9577f037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e75458a-89a5-4535-83b0-bcfcdf8472b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.split(re.escape(' + ') + '|' + re.escape('*'), 'hi + me*4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190467bd-c55d-43e2-96f1-4026e4a346e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(5,4,figsize=(15,20))\n",
    "ax = ax.flatten()\n",
    "for i in ldamodel.print_topics(num_topics=20, num_words=20):\n",
    "    x = []\n",
    "    y = []\n",
    "    count = 0\n",
    "    for j in re.split(re.escape(' + ') + '|' + re.escape('*'), i[1]):\n",
    "        if count % 2 == 0:\n",
    "            y.insert(0,float(j))\n",
    "        else:\n",
    "            x.insert(0,j)\n",
    "        count += 1\n",
    "    ax[i[0]].barh(x,y,height=0.5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b67a169-d4ed-438d-ac19-d3f7302beb73",
   "metadata": {},
   "source": [
    "# TF-IDF (Term Frequency Inverse Document Frequency)\n",
    "\n",
    "TF-IDF is similar to bag-of-words, but it down weights words appearing frequently across lots of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3416752c-d9ac-455b-b982-ddc7cce0923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the model\n",
    "tfidf = gensim.models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d709d9-a14c-408e-b2e1-67d82583e45b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc23d80-e01c-40cd-964c-2aa077283263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply transformation\n",
    "tfidf[corpus[30]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6056c0-7920-47fc-a533-9bc99e2eb4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_transformed = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4e8ef0-9314-4eae-9827-e155bbdcb4c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus_transformed[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287fdb77-fab9-46b2-8e21-d0a315adff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel_tfidf = gensim.models.ldamodel.LdaModel(corpus_transformed, \n",
    "                                           num_topics=20, \n",
    "                                           id2word = dictionary, \n",
    "                                           passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e572e6e-13cb-4e07-a360-ede842fd5d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ldamodel_tfidf.print_topics(num_topics=20, num_words=20):\n",
    "    print(i[0])\n",
    "    print(i[1])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649a45f0-4dec-4241-a167-24ac08a912fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(5,4,figsize=(15,20))\n",
    "ax = ax.flatten()\n",
    "for i in ldamodel_tfidf.print_topics(num_topics=20, num_words=20):\n",
    "    x = []\n",
    "    y = []\n",
    "    count = 0\n",
    "    for j in re.split(re.escape(' + ') + '|' + re.escape('*'), i[1]):\n",
    "        if count % 2 == 0:\n",
    "            y.insert(0,float(j))\n",
    "        else:\n",
    "            x.insert(0,j)\n",
    "        count += 1\n",
    "    ax[i[0]].barh(x,y,height=0.5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f83ec3-5c07-497d-b10f-4dd76c3eef16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
