{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a057f008-5f33-4766-8690-4b4127ab1871",
   "metadata": {},
   "source": [
    "# Introduction to NLP with Python's NLTK\n",
    "\n",
    "* \"NLTK is a leading platform for building Python programs to work with human language data.\" -- NLTK website\n",
    "* https://www.nltk.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aab6efc-a9e7-457b-80e5-1d1ec7417f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8ba4bd-73ab-48ee-b754-6ac21eebaba1",
   "metadata": {},
   "source": [
    "We'll use the first lines of Moby Dick to explore some NLP basics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ba0cbe-0fc6-4bff-8626-5dd38d3e8583",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "Call me Ishmael. Some years ago—never mind how long precisely—having little\n",
    "or no money in my purse, and nothing particular to interest me on shore, \n",
    "I thought I would sail about a little and see the watery part of the world.'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e6cf54-9661-4952-9b43-c82ebd294b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e375e97c-d22b-43c9-9b2c-6352d7bd5ca6",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff627bc-c814-4619-81c4-c1db63d6b668",
   "metadata": {},
   "source": [
    "**Tokenization** breaks the raw text into smaller pieces like sentences and words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712aa087-41c0-45f3-8738-5a98b2e6747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78044409-0671-44c8-9878-58da177e7e47",
   "metadata": {},
   "source": [
    "* `sent_tokenize` takes a string and breaks it down into a list of sentences.\n",
    "* `word_tokenize` takes a string and breaks it down into a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab9cdcc-5403-4106-b53b-d3c229d2c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(text)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b34b48-d148-4e3a-acf4-19fb90214320",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_tokenize(sentences[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f36b8b-c1d3-46c8-9c81-330bc4470dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a19cc1-faa5-44e7-a7a9-5bed514aafa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "words2 = []\n",
    "for s in sentences:\n",
    "    for w in word_tokenize(s):\n",
    "        words2.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cb1f17-3313-4b5f-a86a-a0e4b74ad346",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(words2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01707337-6707-404f-bd64-407d1e977032",
   "metadata": {},
   "source": [
    "## Stopword removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee214cc0-899f-408c-b9b2-2b0d3447f25a",
   "metadata": {},
   "source": [
    "Usually in language analysis we don't want our analysis to be skewed by very common words like 'a', 'the', 'and', etc.  These are stopwords and can be removed before commencing a more detailed analysis.  We often may not want to analyse punctuation marks either when analysing language use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b0ad7f-4558-468d-a6b9-32baa4249904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c12e961-caae-4bf5-96a9-70c22473fbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b123620-daf7-488a-b261-d40f13e48222",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bd6df1-18e9-4fb7-b021-b20557e8574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6d073e-4281-4e0b-9d0c-17d370b2bcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "myStopWords = list(punctuation) + stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a18da5-936d-4d92-84c3-8713f7b8c846",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bbe153-6e7e-45d3-82c5-8bf2aec79829",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsNoStop = []\n",
    "for i in words:\n",
    "    if i not in myStopWords:\n",
    "        wordsNoStop.append(i)\n",
    "print(words)\n",
    "print(wordsNoStop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc7d195-7bf2-466a-826f-bc09c1f16258",
   "metadata": {},
   "source": [
    "We'll use list comprehension to streamline this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ec9ffb-8a70-49bc-94b8-141550c3c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example list comprehension\n",
    "[i for i in [1,2,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccbd133-b9dd-4c0d-8590-dc1f42f07543",
   "metadata": {},
   "outputs": [],
   "source": [
    "[a for a in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea6539a-b775-46d1-ba71-801d90f9f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in [2,3,6,5,7,8,4] if x > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff8395a-6edb-4c27-b0bf-70200f7d2f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsNoStopComp = [w for w in words if w not in myStopWords]\n",
    "print(wordsNoStopComp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32907fd3-f01d-4a1b-b802-95799f1b4f87",
   "metadata": {},
   "source": [
    "## N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1c8796-e654-4680-931e-7e3f206d0dbc",
   "metadata": {},
   "source": [
    "Words that are near to each other can allow us to draw deeper conclusions about a given text. We can split a text into pairs of co-located words (bi-grams), triplets (tri-grams), and generally into n-tuplets (n-grams)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd64e6ed-e03e-419c-b721-9d513389b23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa06922-df24-4905-9c3e-635a8fdb880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = BigramCollocationFinder.from_words(wordsNoStop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cea51ba-80fb-4fe6-ad24-ca68ebd8467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a37ae9d-b73b-4a8d-8388-365f5caf0cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "finder.ngram_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ec0f60-b3b3-4d12-87ea-4d6ab6a92976",
   "metadata": {},
   "outputs": [],
   "source": [
    "finder.ngram_fd.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d059c3f-bbc9-42f7-be5f-ecc77a52033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(finder.ngram_fd.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f730a2-48ce-4610-bd70-021e6ff9d884",
   "metadata": {},
   "source": [
    "## Stemming and Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f65990e-defc-48fa-a95f-66490d7d6d0c",
   "metadata": {},
   "source": [
    "Stemming allows us to improve our estimate of word frequency by combining the counts of similar forms of words (e.g. counting sail, sailing, and sailed as representative of the common stem \"sail\").\n",
    "\n",
    "Tagging helps us to disambiguate words by identifying their part-of-speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1d9c82-1f75-4b8c-964b-4d0ec7a71422",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = 'Ishmael sailed because sailing and wanting to sail was in his blood.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf8742b-0f35-40f3-a256-a7a044fcfe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98952ad0-7d9c-4860-85ef-1d4d76f5b601",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca1c277-be2c-4423-ad2e-df39170294f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d79d46-275b-41eb-ab28-db4439d2f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordLancasterStems = [LancasterStemmer().stem(w) for w in words]\n",
    "wordPorterStems = [PorterStemmer().stem(w) for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693346f4-813d-4364-bb29-c3590a08f0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wordLancasterStems)\n",
    "print(wordPorterStems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5074e03-bfdf-4bbf-94d3-aab6dbe8187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb61bc07-5271-4533-b865-49368c7c301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(word_tokenize('Once upon a time there was a cat.  It was black and fluffy.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89961a5c-df27-46cb-8616-b9690f0210ce",
   "metadata": {},
   "source": [
    "Check out the [Penn Treebank Project list](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e506f81-47c2-43eb-a419-484224a6bacd",
   "metadata": {},
   "source": [
    "## Word sense disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61334f44-001d-4310-b95e-08e8524fbd01",
   "metadata": {},
   "source": [
    "We can further disambiguate words by looking at their synsets.  Synsets are groupings of synonymous words that are conceptually similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdd4f3b-6045-4e9e-8561-fba1f3d6685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "for ss in wordnet.synsets('sail'):\n",
    "    print(ss, ss.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e67adf-ef03-4189-bad8-536c56595c3e",
   "metadata": {},
   "source": [
    "One algorithm for disambiguating a word is the Lesk algorithm, which loosely speaking looks at the definitions of neighboring words to that word and selects the definition that has the highest overlap with these neighboring definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27449865-8d15-4cef-8dee-04576cc3c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.wsd import lesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7167125a-6f2c-4b8d-adaa-77b010c18c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69969cff-c19d-48c8-b850-0e42818effe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSense = lesk(words, 'sail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82581ac0-86ae-42d2-844f-efee455fc747",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wordSense, wordSense.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07527854-5e9c-4427-9c99-a5c5fb740e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSense = lesk(words, 'sailed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d068756-a0cb-4c37-9f8f-485090454aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wordSense, wordSense.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1ba474-0478-493e-befd-9f62c0b98fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSense = lesk(words, 'wanting to sail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2528ff5-714e-436e-99ca-8988b1195be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wordSense, wordSense.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a995f3-b334-47e7-9a22-7fcd86861709",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 'I sailed to Mexico on a boat each winter.'\n",
    "s = lesk(word_tokenize(t), 'sailed')\n",
    "print(s, s.definition())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
