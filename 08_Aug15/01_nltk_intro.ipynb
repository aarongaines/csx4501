{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a057f008-5f33-4766-8690-4b4127ab1871",
   "metadata": {},
   "source": [
    "# Introduction to NLP with Python's NLTK\n",
    "\n",
    "* \"NLTK is a leading platform for building Python programs to work with human language data.\" -- NLTK website\n",
    "* https://www.nltk.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aab6efc-a9e7-457b-80e5-1d1ec7417f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8ba4bd-73ab-48ee-b754-6ac21eebaba1",
   "metadata": {},
   "source": [
    "We'll use the first lines of Moby Dick to explore some NLP basics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ba0cbe-0fc6-4bff-8626-5dd38d3e8583",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "Call me Ishmael. Some years ago—never mind how long precisely—having little\n",
    "or no money in my purse, and nothing particular to interest me on shore, \n",
    "I thought I would sail about a little and see the watery part of the world.'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56e6cf54-9661-4952-9b43-c82ebd294b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call me Ishmael. Some years ago—never mind how long precisely—having little\n",
      "or no money in my purse, and nothing particular to interest me on shore, \n",
      "I thought I would sail about a little and see the watery part of the world.'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e375e97c-d22b-43c9-9b2c-6352d7bd5ca6",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff627bc-c814-4619-81c4-c1db63d6b668",
   "metadata": {},
   "source": [
    "**Tokenization** breaks the raw text into smaller pieces like sentences and words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "712aa087-41c0-45f3-8738-5a98b2e6747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78044409-0671-44c8-9878-58da177e7e47",
   "metadata": {},
   "source": [
    "* `sent_tokenize` takes a string and breaks it down into a list of sentences.\n",
    "* `word_tokenize` takes a string and breaks it down into a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dab9cdcc-5403-4106-b53b-d3c229d2c02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\nCall me Ishmael.', \"Some years ago—never mind how long precisely—having little\\nor no money in my purse, and nothing particular to interest me on shore, \\nI thought I would sail about a little and see the watery part of the world.'\"]\n"
     ]
    }
   ],
   "source": [
    "sentences = sent_tokenize(text)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5b34b48-d148-4e3a-acf4-19fb90214320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Some', 'years', 'ago—never', 'mind', 'how', 'long', 'precisely—having', 'little', 'or', 'no', 'money', 'in', 'my', 'purse', ',', 'and', 'nothing', 'particular', 'to', 'interest', 'me', 'on', 'shore', ',', 'I', 'thought', 'I', 'would', 'sail', 'about', 'a', 'little', 'and', 'see', 'the', 'watery', 'part', 'of', 'the', 'world', '.', \"'\"]\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(sentences[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3f36b8b-c1d3-46c8-9c81-330bc4470dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Call', 'me', 'Ishmael', '.', 'Some', 'years', 'ago—never', 'mind', 'how', 'long', 'precisely—having', 'little', 'or', 'no', 'money', 'in', 'my', 'purse', ',', 'and', 'nothing', 'particular', 'to', 'interest', 'me', 'on', 'shore', ',', 'I', 'thought', 'I', 'would', 'sail', 'about', 'a', 'little', 'and', 'see', 'the', 'watery', 'part', 'of', 'the', 'world', '.', \"'\"]\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42a19cc1-faa5-44e7-a7a9-5bed514aafa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "words2 = []\n",
    "for s in sentences:\n",
    "    for w in word_tokenize(s):\n",
    "        words2.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4cb1f17-3313-4b5f-a86a-a0e4b74ad346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Call', 'me', 'Ishmael', '.', 'Some', 'years', 'ago—never', 'mind', 'how', 'long', 'precisely—having', 'little', 'or', 'no', 'money', 'in', 'my', 'purse', ',', 'and', 'nothing', 'particular', 'to', 'interest', 'me', 'on', 'shore', ',', 'I', 'thought', 'I', 'would', 'sail', 'about', 'a', 'little', 'and', 'see', 'the', 'watery', 'part', 'of', 'the', 'world', '.', \"'\"]\n"
     ]
    }
   ],
   "source": [
    "print(words2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01707337-6707-404f-bd64-407d1e977032",
   "metadata": {},
   "source": [
    "## Stopword removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee214cc0-899f-408c-b9b2-2b0d3447f25a",
   "metadata": {},
   "source": [
    "Usually in language analysis we don't want our analysis to be skewed by very common words like 'a', 'the', 'and', etc.  These are stopwords and can be removed before commencing a more detailed analysis.  We often may not want to analyse punctuation marks either when analysing language use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06b0ad7f-4558-468d-a6b9-32baa4249904",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     c:\\Users\\chief\\.conda\\envs\\geoprj\\lib\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c12e961-caae-4bf5-96a9-70c22473fbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b123620-daf7-488a-b261-d40f13e48222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55bd6df1-18e9-4fb7-b021-b20557e8574d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "print(list(punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b6d073e-4281-4e0b-9d0c-17d370b2bcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "myStopWords = list(punctuation) + stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27a18da5-936d-4d92-84c3-8713f7b8c846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Call', 'me', 'Ishmael', '.', 'Some', 'years', 'ago—never', 'mind', 'how', 'long', 'precisely—having', 'little', 'or', 'no', 'money', 'in', 'my', 'purse', ',', 'and', 'nothing', 'particular', 'to', 'interest', 'me', 'on', 'shore', ',', 'I', 'thought', 'I', 'would', 'sail', 'about', 'a', 'little', 'and', 'see', 'the', 'watery', 'part', 'of', 'the', 'world', '.', \"'\"]\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86bbe153-6e7e-45d3-82c5-8bf2aec79829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Call', 'me', 'Ishmael', '.', 'Some', 'years', 'ago—never', 'mind', 'how', 'long', 'precisely—having', 'little', 'or', 'no', 'money', 'in', 'my', 'purse', ',', 'and', 'nothing', 'particular', 'to', 'interest', 'me', 'on', 'shore', ',', 'I', 'thought', 'I', 'would', 'sail', 'about', 'a', 'little', 'and', 'see', 'the', 'watery', 'part', 'of', 'the', 'world', '.', \"'\"]\n",
      "['Call', 'Ishmael', 'Some', 'years', 'ago—never', 'mind', 'long', 'precisely—having', 'little', 'money', 'purse', 'nothing', 'particular', 'interest', 'shore', 'I', 'thought', 'I', 'would', 'sail', 'little', 'see', 'watery', 'part', 'world']\n"
     ]
    }
   ],
   "source": [
    "wordsNoStop = []\n",
    "for i in words:\n",
    "    if i not in myStopWords:\n",
    "        wordsNoStop.append(i)\n",
    "print(words)\n",
    "print(wordsNoStop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc7d195-7bf2-466a-826f-bc09c1f16258",
   "metadata": {},
   "source": [
    "We'll use list comprehension to streamline this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6ec9ffb-8a70-49bc-94b8-141550c3c67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example list comprehension\n",
    "[i for i in [1,2,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ccbd133-b9dd-4c0d-8590-dc1f42f07543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a for a in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ea6539a-b775-46d1-ba71-801d90f9f179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 7, 8]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in [2,3,6,5,7,8,4] if x > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ff8395a-6edb-4c27-b0bf-70200f7d2f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Call', 'Ishmael', 'Some', 'years', 'ago—never', 'mind', 'long', 'precisely—having', 'little', 'money', 'purse', 'nothing', 'particular', 'interest', 'shore', 'I', 'thought', 'I', 'would', 'sail', 'little', 'see', 'watery', 'part', 'world']\n"
     ]
    }
   ],
   "source": [
    "wordsNoStopComp = [w for w in words if w not in myStopWords]\n",
    "print(wordsNoStopComp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32907fd3-f01d-4a1b-b802-95799f1b4f87",
   "metadata": {},
   "source": [
    "## N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1c8796-e654-4680-931e-7e3f206d0dbc",
   "metadata": {},
   "source": [
    "Words that are near to each other can allow us to draw deeper conclusions about a given text. We can split a text into pairs of co-located words (bi-grams), triplets (tri-grams), and generally into n-tuplets (n-grams)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd64e6ed-e03e-419c-b721-9d513389b23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fa06922-df24-4905-9c3e-635a8fdb880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = BigramCollocationFinder.from_words(wordsNoStop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cea51ba-80fb-4fe6-ad24-ca68ebd8467f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nltk.collocations.BigramCollocationFinder at 0x2d1213549a0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a37ae9d-b73b-4a8d-8388-365f5caf0cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('Call', 'Ishmael'): 1, ('Ishmael', 'Some'): 1, ('Some', 'years'): 1, ('years', 'ago—never'): 1, ('ago—never', 'mind'): 1, ('mind', 'long'): 1, ('long', 'precisely—having'): 1, ('precisely—having', 'little'): 1, ('little', 'money'): 1, ('money', 'purse'): 1, ...})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.ngram_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64ec0f60-b3b3-4d12-87ea-4d6ab6a92976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(('Call', 'Ishmael'), 1), (('Ishmael', 'Some'), 1), (('Some', 'years'), 1), (('years', 'ago—never'), 1), (('ago—never', 'mind'), 1), (('mind', 'long'), 1), (('long', 'precisely—having'), 1), (('precisely—having', 'little'), 1), (('little', 'money'), 1), (('money', 'purse'), 1), (('purse', 'nothing'), 1), (('nothing', 'particular'), 1), (('particular', 'interest'), 1), (('interest', 'shore'), 1), (('shore', 'I'), 1), (('I', 'thought'), 1), (('thought', 'I'), 1), (('I', 'would'), 1), (('would', 'sail'), 1), (('sail', 'little'), 1), (('little', 'see'), 1), (('see', 'watery'), 1), (('watery', 'part'), 1), (('part', 'world'), 1)])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.ngram_fd.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d059c3f-bbc9-42f7-be5f-ecc77a52033a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Call', 'Ishmael'), 1),\n",
       " (('I', 'thought'), 1),\n",
       " (('I', 'would'), 1),\n",
       " (('Ishmael', 'Some'), 1),\n",
       " (('Some', 'years'), 1),\n",
       " (('ago—never', 'mind'), 1),\n",
       " (('interest', 'shore'), 1),\n",
       " (('little', 'money'), 1),\n",
       " (('little', 'see'), 1),\n",
       " (('long', 'precisely—having'), 1),\n",
       " (('mind', 'long'), 1),\n",
       " (('money', 'purse'), 1),\n",
       " (('nothing', 'particular'), 1),\n",
       " (('part', 'world'), 1),\n",
       " (('particular', 'interest'), 1),\n",
       " (('precisely—having', 'little'), 1),\n",
       " (('purse', 'nothing'), 1),\n",
       " (('sail', 'little'), 1),\n",
       " (('see', 'watery'), 1),\n",
       " (('shore', 'I'), 1),\n",
       " (('thought', 'I'), 1),\n",
       " (('watery', 'part'), 1),\n",
       " (('would', 'sail'), 1),\n",
       " (('years', 'ago—never'), 1)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(finder.ngram_fd.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f730a2-48ce-4610-bd70-021e6ff9d884",
   "metadata": {},
   "source": [
    "## Stemming and Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f65990e-defc-48fa-a95f-66490d7d6d0c",
   "metadata": {},
   "source": [
    "Stemming allows us to improve our estimate of word frequency by combining the counts of similar forms of words (e.g. counting sail, sailing, and sailed as representative of the common stem \"sail\").\n",
    "\n",
    "Tagging helps us to disambiguate words by identifying their part-of-speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b1d9c82-1f75-4b8c-964b-4d0ec7a71422",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = 'Ishmael sailed because sailing and wanting to sail was in his blood.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cf8742b-0f35-40f3-a256-a7a044fcfe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98952ad0-7d9c-4860-85ef-1d4d76f5b601",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ca1c277-be2c-4423-ad2e-df39170294f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ishmael', 'sailed', 'because', 'sailing', 'and', 'wanting', 'to', 'sail', 'was', 'in', 'his', 'blood', '.']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6d79d46-275b-41eb-ab28-db4439d2f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordLancasterStems = [LancasterStemmer().stem(w) for w in words]\n",
    "wordPorterStems = [PorterStemmer().stem(w) for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "693346f4-813d-4364-bb29-c3590a08f0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ishmael', 'sail', 'becaus', 'sail', 'and', 'want', 'to', 'sail', 'was', 'in', 'his', 'blood', '.']\n",
      "['ishmael', 'sail', 'becaus', 'sail', 'and', 'want', 'to', 'sail', 'wa', 'in', 'hi', 'blood', '.']\n"
     ]
    }
   ],
   "source": [
    "print(wordLancasterStems)\n",
    "print(wordPorterStems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5074e03-bfdf-4bbf-94d3-aab6dbe8187c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ishmael', 'NNP'),\n",
       " ('sailed', 'VBD'),\n",
       " ('because', 'IN'),\n",
       " ('sailing', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('wanting', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('sail', 'VB'),\n",
       " ('was', 'VBD'),\n",
       " ('in', 'IN'),\n",
       " ('his', 'PRP$'),\n",
       " ('blood', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb61bc07-5271-4533-b865-49368c7c301a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Once', 'RB'),\n",
       " ('upon', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('time', 'NN'),\n",
       " ('there', 'EX'),\n",
       " ('was', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('cat', 'NN'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('black', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('fluffy', 'JJ'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(word_tokenize('Once upon a time there was a cat.  It was black and fluffy.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89961a5c-df27-46cb-8616-b9690f0210ce",
   "metadata": {},
   "source": [
    "Check out the [Penn Treebank Project list](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e506f81-47c2-43eb-a419-484224a6bacd",
   "metadata": {},
   "source": [
    "## Word sense disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61334f44-001d-4310-b95e-08e8524fbd01",
   "metadata": {},
   "source": [
    "We can further disambiguate words by looking at their synsets.  Synsets are groupings of synonymous words that are conceptually similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03709368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ecdd4f3b-6045-4e9e-8561-fba1f3d6685b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('sail.n.01') a large piece of fabric (usually canvas fabric) by means of which wind is used to propel a sailing vessel\n",
      "Synset('cruise.n.01') an ocean trip taken for pleasure\n",
      "Synset('sail.n.03') any structure that resembles a sail\n",
      "Synset('sail.v.01') traverse or travel on (a body of water)\n",
      "Synset('sweep.v.02') move with sweeping, effortless, gliding motions\n",
      "Synset('sail.v.03') travel on water propelled by wind\n",
      "Synset('voyage.v.01') travel on water propelled by wind or by other means\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "for ss in wordnet.synsets('sail'):\n",
    "    print(ss, ss.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e67adf-ef03-4189-bad8-536c56595c3e",
   "metadata": {},
   "source": [
    "One algorithm for disambiguating a word is the Lesk algorithm, which loosely speaking looks at the definitions of neighboring words to that word and selects the definition that has the highest overlap with these neighboring definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "27449865-8d15-4cef-8dee-04576cc3c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.wsd import lesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7167125a-6f2c-4b8d-adaa-77b010c18c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ishmael', 'sailed', 'because', 'sailing', 'and', 'wanting', 'to', 'sail', 'was', 'in', 'his', 'blood', '.']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69969cff-c19d-48c8-b850-0e42818effe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSense = lesk(words, 'sail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82581ac0-86ae-42d2-844f-efee455fc747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('sail.n.01') a large piece of fabric (usually canvas fabric) by means of which wind is used to propel a sailing vessel\n"
     ]
    }
   ],
   "source": [
    "print(wordSense, wordSense.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "07527854-5e9c-4427-9c99-a5c5fb740e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSense = lesk(words, 'sailed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d068756-a0cb-4c37-9f8f-485090454aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('voyage.v.01') travel on water propelled by wind or by other means\n"
     ]
    }
   ],
   "source": [
    "print(wordSense, wordSense.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be1ba474-0478-493e-befd-9f62c0b98fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSense = lesk(words, 'wanting to sail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2528ff5-714e-436e-99ca-8988b1195be3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'definition'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\personal\\ucla_ext\\Intro to Data Science\\csx4501\\08_Aug15\\01_nltk_intro.ipynb Cell 60\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/personal/ucla_ext/Intro%20to%20Data%20Science/csx4501/08_Aug15/01_nltk_intro.ipynb#Y112sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(wordSense, wordSense\u001b[39m.\u001b[39;49mdefinition())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'definition'"
     ]
    }
   ],
   "source": [
    "print(wordSense, wordSense.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a7a995f3-b334-47e7-9a22-7fcd86861709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('voyage.v.01') travel on water propelled by wind or by other means\n"
     ]
    }
   ],
   "source": [
    "t = 'I sailed to Mexico on a boat each winter.'\n",
    "s = lesk(word_tokenize(t), 'sailed')\n",
    "print(s, s.definition())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('geoprj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "23234625f55973f7a58126a35d86facfdbb1213f4cf262be4a4984331c60271a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
